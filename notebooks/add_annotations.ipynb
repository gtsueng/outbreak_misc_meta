{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script adds miscelleneous annotations generated from other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def find_gen_path():\n",
    "    tmp_dir = os.getcwd()\n",
    "    while 'topic_classifier' not in os.listdir(tmp_dir):\n",
    "        tmp_dir = os.path.dirname(tmp_dir)\n",
    "    return(tmp_dir)\n",
    "\n",
    "def fetch_path_dict():\n",
    "    general_path = find_gen_path()\n",
    "    topic_folder = os.path.join(general_path,'topic_classifier')\n",
    "    topic_results = os.path.join(topic_folder,'results')\n",
    "    alt_path = os.path.join(general_path,'covid_altmetrics')\n",
    "    alt_results = os.path.join(alt_path,'results')\n",
    "    preprint_path = os.path.join(general_path,'outbreak_preprint_matcher')\n",
    "    preprint_results = os.path.join(preprint_path,'results')\n",
    "    preprint_dumps = os.path.join(preprint_results,'update dumps')\n",
    "    loe_ann_path = os.path.join(general_path,'covid19_LST_annotations')\n",
    "    loe_results = os.path.join(loe_ann_path,'results')\n",
    "    path_dict = {\n",
    "        'topics_file':os.path.join(topic_results,'topicCats.json'),\n",
    "        'altmetrics_file':os.path.join(alt_results,'altmetric_annotations.json'),\n",
    "        'litcovid_updates':os.path.join(preprint_dumps,'litcovid_update_file.json'),\n",
    "        'preprint_updates':os.path.join(preprint_dumps,'preprint_update_file.json'),\n",
    "        'loe_annotations':os.path.join(loe_results,'loe_annotations.json')\n",
    "        }\n",
    "    return(path_dict)\n",
    "\n",
    "\n",
    "def fetch_annotation(path_dict,source,outbreak_id):\n",
    "    with open(path_dict[source],'r') as infile:\n",
    "        ann_dict = json.load(infile)\n",
    "    ann_info = [x for x in ann_dict if x[\"_id\"]==outbreak_id]\n",
    "    try:\n",
    "        return(ann_info[0])\n",
    "    except:\n",
    "        return(ann_info)\n",
    "\n",
    "    \n",
    "def add_anns(doc):\n",
    "    path_dict = fetch_path_dict()\n",
    "    ## add corrections\n",
    "    if doc['@type']=='Publication':\n",
    "        if 'pmid' in doc['_id']:\n",
    "            ## doc is from litcovid\n",
    "            corrections = fetch_annotation(path_dict,'litcovid_updates',doc['_id'])\n",
    "            loe_info = fetch_annotation(path_dict,'loe_annotations',doc['_id'])\n",
    "        else:\n",
    "            corrections = fetch_annotation(path_dict,'preprint_updates',doc['_id'])\n",
    "            loe_info = None\n",
    "        if corrections != None:\n",
    "            if 'correction' in doc.keys():  ## check if correction field already used\n",
    "                try:\n",
    "                    doc['correction'].append(corrections)\n",
    "                except:\n",
    "                    correct_object = doc['correction']\n",
    "                    doc['correction']=[correct_object,corrections]\n",
    "            else:\n",
    "                doc['correction']=corrections\n",
    "        if loe_info != None:\n",
    "            doc['evaluations'] = loe_info['evaluations']\n",
    "            if 'citedBy' in doc.keys():\n",
    "                doc['citedBy'].append(loe_info['citedBy'])\n",
    "            else:\n",
    "                doc['citedBy'] = []\n",
    "                doc['citedBy'].append(loe_info['citedBy'])\n",
    "    ## add topic_cats\n",
    "    topic_cats = fetch_annotation(path_dict,'topics_file',doc['_id'])\n",
    "    if topic_cats != None:\n",
    "        doc['topicCategory']=topic_cats\n",
    "    ## add altmetrics\n",
    "    altinfo = fetch_annotation(path_dict,'altmetrics_file',doc['_id'])\n",
    "    if altinfo != None:\n",
    "        if 'evaluations' in doc.keys():\n",
    "            try:\n",
    "                doc['evaluations'].append(altinfo['evaluations'][0])\n",
    "            except:\n",
    "                eval_object = doc['evaluations']\n",
    "                doc['evaluations']=[eval_object,altinfo['evaluations'][0]]\n",
    "        else:\n",
    "            doc['evaluations'] = altinfo['evaluations']       \n",
    "    return(doc)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test speed when using list comprehension instead of loops to find an id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Old functions (ignore these as they are slower)\n",
    "            \n",
    "\n",
    "def fetch_topics(path_dict,outbreak_id):\n",
    "    with open(path_dict['topics_file']) as infile:\n",
    "        topics_dict = json.load(infile)\n",
    "    for i in range(len(topics_dict)):\n",
    "        if topics_dict[i]['_id']==outbreak_id:\n",
    "            topicinfo = topics_dict[i]\n",
    "            return(topicinfo)    \n",
    "\n",
    "def fetch_preprint_updates(path_dict,preprint_id):\n",
    "    with open(path_dict['preprint_updates'],'r') as infile:\n",
    "        preprint_dict = json.load(infile)\n",
    "    for i in range(len(preprint_dict)):\n",
    "        if preprint_dict[i]['_id']==preprint_id:\n",
    "            preprint_info = preprint_dict[i]\n",
    "            return(preprint_info)\n",
    "\n",
    "def fetch_reviewed_updates(path_dict,litcovid_id):\n",
    "    with open(path_dict['litcovid_updates'],'r') as infile:\n",
    "        litcovid_dict = json.load(infile)\n",
    "    for i in range(len(litcovid_dict)):\n",
    "        if litcovid_dict[i]['_id']==litcovid_id:\n",
    "            litcovid_info = litcovid_dict[i]\n",
    "            return(litcovid_info)\n",
    "    \n",
    "def check_altmetrics(path_dict,outbreak_id):\n",
    "    with open(path_dict['altmetrics_file']) as infile:\n",
    "        altmetrics_dict = json.load(infile)\n",
    "    for i in range(len(altmetrics_dict)):\n",
    "        if altmetrics_dict[i]['_id']==outbreak_id:\n",
    "            altinfo = altmetrics_dict[i]\n",
    "            return(altinfo)\n",
    "\n",
    "def check_loe_anns(path_dict,outbreak_id):\n",
    "    with open(path_dict['loe_annotations']) as infile:\n",
    "        loe_dict = json.load(infile)\n",
    "    for i in range(len(loe_dict)):\n",
    "        if loe_dict[i]['_id']==outbreak_id:\n",
    "            loe_info = loe_dict[i]\n",
    "            return(loe_info)\n",
    "\n",
    "def add_anns_old(doc):\n",
    "    path_dict = fetch_path_dict()\n",
    "    ## add corrections\n",
    "    if doc['@type']=='Publication':\n",
    "        if 'pmid' in doc['_id']:\n",
    "            ## doc is from litcovid\n",
    "            corrections = fetch_reviewed_updates(path_dict,doc['_id'])\n",
    "            loe_info = check_loe_anns(path_dict,doc['_id'])\n",
    "        else:\n",
    "            corrections = fetch_preprint_updates(path_dict,doc['_id'])\n",
    "            loe_info = None\n",
    "        if corrections != None:\n",
    "            if 'correction' in doc.keys():  ## check if correction field already used\n",
    "                try:\n",
    "                    doc['correction'].append(corrections)\n",
    "                except:\n",
    "                    correct_object = doc['correction']\n",
    "                    doc['correction']=[correct_object,corrections]\n",
    "            else:\n",
    "                doc['correction']=corrections\n",
    "        if loe_info != None:\n",
    "            doc['evaluations'] = loe_info['evaluations']\n",
    "            if 'citedBy' in doc.keys():\n",
    "                doc['citedBy'].append(loe_info['citedBy'])\n",
    "            else:\n",
    "                doc['citedBy'] = []\n",
    "                doc['citedBy'].append(loe_info['citedBy'])\n",
    "    ## add topic_cats\n",
    "    topic_cats = fetch_topics(path_dict,doc['_id'])\n",
    "    if topic_cats != None:\n",
    "        doc['topicCategory']=topic_cats\n",
    "    ## add altmetrics\n",
    "    altinfo = check_altmetrics(path_dict,doc['_id'])\n",
    "    if altinfo != None:\n",
    "        if 'evaluations' in doc.keys():\n",
    "            doc['evaluations'].append(altinfo['evaluations'][0])\n",
    "        else:\n",
    "            doc['evaluations'] = altinfo['evaluations']       \n",
    "    return(doc)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing impact of list comprehension in a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dict = fetch_path_dict()\n",
    "litcovid_list = ['pmid32562477','pmid34385356','pmid33582134','pmid32835303','pmid32264791',\n",
    "                 'pmid32424571','pmid32650645','pmid32302377','pmid32463365','pmid32220655',\n",
    "                 'pmid32502733','pmid32339844','pmid32428990','pmid32526193','pmid32388471']#,\n",
    "                 #'pmid39546836','pmid32403007','pmid32526655','pmid32594937','pmid32374400',\n",
    "                 #'pmid32376627','pmid32658859','pmid32434518','pmid32408453','pmid32547891',\n",
    "                 #'pmid32234804','pmid32369759','pmid32552016','pmid32627200','pmid32614817',\n",
    "                 #'pmid32651556','pmid32495918','pmid32344319','pmid32239761','pmid32404476',\n",
    "                 #'pmid32183920','pmid32234121','pmid39546830','pmid39546831','pmid39546832']\n",
    "preprint_list = ['2020.04.07.20052340','2020.05.01.20077743','2020.01.28.20019224',\n",
    "                 '2020.03.24.20043018','2020.05.07.20093674','2020.04.16.20068379',\n",
    "                 '2020.05.11.20097808','2020.03.26.20040709','2020.01.28.20019224',\n",
    "                 '2020.05.03.066266','2020.03.17.20037671']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.1 ms ± 4.56 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "litcovid_results = []\n",
    "for litcovid_id in litcovid_list:\n",
    "    litcovid_info = fetch_reviewed_updates(path_dict,litcovid_id)\n",
    "    litcovid_results.append(litcovid_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.8 ms ± 662 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "litcovid_results = []\n",
    "for litcovid_id in litcovid_list:\n",
    "    litcovid_info = fetch_reviewed_updates_list(path_dict,litcovid_id)\n",
    "    litcovid_results.append(litcovid_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing impact of list comprehension in overall function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "json_docs = []\n",
    "for each_id in list(set(litcovid_list).union(set(preprint_list))):\n",
    "    r = requests.get(\"https://api.outbreak.info/resources/resource/\"+each_id)\n",
    "    doc = json.loads(r.text)\n",
    "    json_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.46 s ± 86.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "doclist = []\n",
    "for doc in json_docs:\n",
    "    jdoc = add_anns_old(doc)\n",
    "    doclist.append(jdoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12 s ± 32.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "listdoclist = []\n",
    "for doc in json_docs:\n",
    "    jdoc = add_anns(doc)\n",
    "    listdoclist.append(jdoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code using the list comprehension is faster by a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing functions or parts of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_dict['litcovid_updates'],'r') as infile:\n",
    "    preprint_dict = json.load(infile)\n",
    "for i in range(len(preprint_dict)):\n",
    "    if preprint_dict[i]['_id']=='pmid32562477':\n",
    "        print(preprint_dict[i])\n",
    "        break\n",
    "\n",
    "print(preprint_dict[0].keys())\n",
    "if 'correction' in preprint_dict[0].keys():\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dict = fetch_path_dict()\n",
    "litcovid_info = fetch_reviewed_updates(path_dict,'pmid32562477')\n",
    "check = fetch_preprint_updates(path_dict,'pmid32562477')\n",
    "print(litcovid_info)\n",
    "if check == None:\n",
    "    print('no check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_dict['altmetrics_file']) as infile:\n",
    "    altmetrics_dict = json.load(infile)\n",
    "print(altmetrics_dict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
